{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca78a313",
   "metadata": {},
   "source": [
    "# Chapter1 : Prompt Chaining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b9ad77",
   "metadata": {},
   "source": [
    "- Sometimes referred to as pipeline pattern, represents a powerful paradigm for handling intricate tasks. Rather than expecting an LLM to solve a complex problem in a single, monolithic step, Prompt chaining advocates for a divide and conquer strategy. \n",
    "- Core idea = break down the original into sequence of smaller, more manageble sub- problems. \n",
    "- This Sequential processing technique inherently introduces modularity and clarity into the interactions with LLMs. \n",
    "- Prompt Chainingis not just about breaking down problems;  it also enables the integration of external knowledge and tooks. At each step, the LLM can be instructed to interact with external systems, APIs and databases, enriching its knowledge and abilities beyond its internal training data.\n",
    "- By strategically structuring the sequence of prompts, an agent can engage in tasks requiring multi-step reasoning, planning and decision-making. Such agent workflow can mimic human thought processes more closely, allowing for more natural and effective interactions with complex domains and systems. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c45833a",
   "metadata": {},
   "source": [
    "##### **Limitations of single prompts:** \n",
    "for mutifaceted tasks, using a single, complex prompt for an LLM can be inefficient, causing the model to struggle with constraints and instructins, potentially leading to instruction neglect where parts of the prompt are overlooked, COntextual drift where the model loses track of the initial context, error propagation where early errors amplify.\n",
    "\n",
    "##### **Enhanced Reliability Through Sequential Decomposotion**: \n",
    "Address these challenges by breaking the complex task into a focused, sequential workflow, which significantly improves reliability and control.\n",
    "Eg,.\n",
    "1. Intial Prompt (Summarization): \"Summarize the key findings of the following market research report:[text].\" The model's sole focus is summarization, increasing the accuracy of this intial step.\n",
    "2. Second Prompt (trend Identification): \"Using the summary, identify the top 3 emerging trends and extract the specific data points that support each trend: [output from step 1].\" This prompt is now more constrained and builds directly upon a validated output.\n",
    "3. Third Prompt (Email Composition): \"Draft a concise email to the marketing team that outlines the following trends and their supporting data: [output from step 2].\"\n",
    "\n",
    "- Each step is simpler and less ambiguous\n",
    "\n",
    "##### **The Role of Structed Output:**\n",
    "1. The reliability of a prompt chain is highly dependent on the integrity of the data passed between steps. If the output of one prompt is ambiguous or poorly formatted, the subsequent prompt may fail due to faulty input. To mitigate this, specifying a structured output format, such as JSON or XML is crucial.\n",
    "```{\n",
    " \"trends\": [\n",
    "   {\n",
    "     \"trend_name\": \"AI-Powered Personalization\",\n",
    "     \"supporting_data\": \"73% of consumers prefer to do business with brands that use personal information to make their shopping experiences more relevant.\"\n",
    "   },\n",
    "   {\n",
    "     \"trend_name\": \"Sustainable and Ethical Brands\",\n",
    "     \"supporting_data\": \"Sales of products with ESG-related claims grew 28% over the last five years, compared to 20% for products without.\"\n",
    "   }\n",
    " ]\n",
    "}\n",
    "```\n",
    "2. This structured format ensures that the data is machine-readable and can be precisely parsed and inserted into the next prompt without ambiguit. This practice minimizes errors that can arise from interpreting natural language and is key component in building robust, multi-step LLM-based systems.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50d0c1e",
   "metadata": {},
   "source": [
    "### **Practical Applications and Use Cases**\n",
    "\n",
    "1. **Information Processing Workflows:** Many tasks involve processing raw information through multiple transformation. \n",
    "For instance, summarizing a document, extracting key entities, and then using those entities to query a database or generate a report.\n",
    "* Prompt 1: Extract text content from a given URL or document.\n",
    "* Prompt 2: Summarized the cleaned text\n",
    "* Prompt 3: Extract specific entities (e.g. names, dates, location) from the summary or original text.\n",
    "* Prompt 4: Use the entities to search an internal knowledge base.\n",
    "* Prompt 5: Generate a final report incorporating the summary, entities, and search results.\n",
    "\n",
    "2. **Complex Query Answering:** Answering complex questions that require multiple steps of reasoning or information retrieval is a prime use case. \n",
    "For Example , \"What were the main causes of the stock market crash in 1929, and how did government policy respond?\"\n",
    "* Prompt 1: Identify the core sub-questions in the user's query (causes of crash, government response).\n",
    "* Prompt 2: Research or retrieve information specifically about the causes of the 1929 crash.\n",
    "* Prompt 3: Research or retrieve information specifically about the government's policy response to the 1929 stock market crash.\n",
    "* Prompt 4: Synthesize the information from steps 2 and 3 into a coherent answer to the original query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "021e79e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_fact(topic):\n",
    "    url = \"https://api.perplexity.ai/chat/completions\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\",\"Content-Type\": \"application/json\"}\n",
    "    data = {\"model\": \"sonar-pro\",   # Or another available model\n",
    "    \"messages\": [ \n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": f\"Tell me an interesting fact about {topic} that most people dont know\"}\n",
    "    ],\"max_tokens\": 500,\"temperature\": 0.7}\n",
    "    \n",
    "    try:\n",
    "        response =  requests.post(url, headers=headers, json = data)\n",
    "        result = response.json()\n",
    "        return result[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"error making API request:{str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1090625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One interesting fact about **AirPods** that most people don't know is that you can use a feature called **Live Listen**, which turns your iPhone into a remote microphone and streams the audio directly to your AirPods[3][5]. This feature was originally designed as an accessibility tool to help people with hearing difficulties, allowing them to place their iPhone closer to a sound source (like a speaker or a person talking) to better hear what's being said through their AirPods. However, it has also been creatively used in situations such as listening to a distant speaker in a lecture hall or even as a makeshift baby monitor[3][5]. \n",
      "\n",
      "This feature is accessible through the iPhone's Control Center under the \"Hearing\" option and works with most AirPods models.\n"
     ]
    }
   ],
   "source": [
    "test_fact = get_daily_fact(\"airpods\")\n",
    "print(test_fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797821fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
